#  Seefood iOS13- My Version. 

Just decided to have a little fun with this project from Angena Yu's iOS development bootcamp improve it's usefulness. I made the following changes

* Used Apple's SF symbols on an initial screen that allows the user to use the camera or an image from their photo library.
* Implemented a blur effect view with an activity spinner that runs while CoreML is processing the image.
* Implemented a table-view where the user can see the first 10 most probable results. 

![Screenshot 1]
(./Screenshots/screenshot1.png)

![Screenshot 2]
(./Screenshots/screenshot2.png)

![Screenshot 3]
(./Screenshots/screenshot3.png)

